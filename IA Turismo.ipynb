{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d62d925",
   "metadata": {},
   "source": [
    "#  Projeto de Roteiriza√ß√£o Tur√≠stica \n",
    "\n",
    "Este notebook implementa o projeto completo de recomenda√ß√£o tur√≠stica com RAG, utilizando:\n",
    "- `Router Chain` para classificar a pergunta\n",
    "- Cadeias espec√≠ficas: roteiro, log√≠stica, info local\n",
    "- Pinecone para base vetorial com RAG\n",
    "- LLM da Groq para gerar respostas\n",
    "\n",
    "\n",
    "Aluna: Mariana Santos Rangel - SAEG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30418b8",
   "metadata": {},
   "source": [
    "## 1. Setup: Instala√ß√£o e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b1b8fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariana/venv310/lib/python3.10/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Pinecone\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict\n",
    "from langchain_pinecone import Pinecone as PineconeVectorStore\n",
    "import time\n",
    "from unidecode import unidecode\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab608823",
   "metadata": {},
   "source": [
    "## 2. Configura√ß√£o de Diret√≥rios e Caminhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leitura das chaves\n",
    "load_dotenv(\"diretorio/.env\", override=True)\n",
    "\n",
    "# Caminho do dataset tur√≠stico\n",
    "data_path = \"diretorio/dados_turisticos.jsonl\"\n",
    "\n",
    "# Diret√≥rio para salvar artefatos do projeto (textos + vetores)\n",
    "art_dir = pathlib.Path(\"artifacts\")\n",
    "art_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Caminhos de sa√≠da\n",
    "out_texts = art_dir / \"docs.jsonl\"\n",
    "out_vec = art_dir / \"vectors.npy\"\n",
    "\n",
    "# Campos obrigat√≥rios do JSON\n",
    "REQUIRED = [\n",
    "    \"id\", \"city\", \"type\", \"name\", \"description\",\n",
    "    \"tags\", \"location\", \"hours\", \"price_range\", \"safety_tips\", \"lang\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4192a533",
   "metadata": {},
   "source": [
    "## 3. Fun√ß√µes de Normaliza√ß√£o e Convers√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b632ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do .jsonl\n",
    "def load_jsonl(path: str) -> List[Dict]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line.strip()) for line in f if line.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea7b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garante presen√ßa dos campos obrigat√≥rios\n",
    "def normalize(rec: Dict) -> Dict:\n",
    "    norm = {k: rec.get(k) for k in REQUIRED}\n",
    "    norm[\"tags\"] = norm.get(\"tags\") or []\n",
    "    return norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06240761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera documento do LangChain\n",
    "def to_document(rec: Dict) -> Document:\n",
    "    tags = \", \".join(rec.get(\"tags\", []))\n",
    "    content = (\n",
    "        f\"{rec['name']} ‚Äî {rec['type']} em {rec['city']} ({rec['location']}). \"\n",
    "        f\"{rec['description']} | Hor√°rios: {rec['hours']} | Pre√ßo: {rec['price_range']} | \"\n",
    "        f\"Tags: {tags} | Dicas: {rec['safety_tips']}\"\n",
    "    )\n",
    "    meta = {k: rec[k] for k in rec if k != \"city\"}\n",
    "  \n",
    "    return Document(page_content=content, metadata=meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad82cb8",
   "metadata": {},
   "source": [
    "## 4. Chunking (divis√£o dos documentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73b31c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide os textos longos em partes menores\n",
    "def chunk_docs(docs: List[Document]) -> List[Document]:\n",
    "    return RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=80).split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe07a5d",
   "metadata": {},
   "source": [
    "## 5. Gerador de Embeddings (MiniLM-L6-v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d1d5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedder():\n",
    "    return HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c270d3",
   "metadata": {},
   "source": [
    "## 6. Execu√ß√£o do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "846b7338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa o pipeline de processamento da base\n",
    "raw = load_jsonl(data_path)\n",
    "docs = [to_document(normalize(r)) for r in raw]\n",
    "chunks = chunk_docs(docs)\n",
    "embedder = get_embedder()\n",
    "vectors = np.array(embedder.embed_documents([d.page_content for d in chunks]), dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aa1b3b",
   "metadata": {},
   "source": [
    "## 7. Salvando os vetores e textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f1a487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva textos com metadados\n",
    "with open(out_texts, \"w\", encoding=\"utf-8\") as f:\n",
    "    for doc in chunks:\n",
    "        record = {\n",
    "            \"text\": doc.page_content,\n",
    "            \"metadata\": doc.metadata\n",
    "        }\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Salva vetor numpy\n",
    "np.save(out_vec, vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf31cf6",
   "metadata": {},
   "source": [
    "## 8. Pinecone: Conex√£o e Indexa√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea48040c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conectado ao √≠ndice: ia-turismo\n"
     ]
    }
   ],
   "source": [
    "# Conecta √† conta\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index_name = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "\n",
    "# Exclua √≠ndice antigo se existir\n",
    "if index_name in [i[\"name\"] for i in pc.list_indexes()]:\n",
    "    pc.delete_index(index_name)\n",
    "    time.sleep(2)\n",
    "# Cria √≠ndice se n√£o existir\n",
    "if index_name not in [i[\"name\"] for i in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "# Conecta ao √≠ndice\n",
    "index = pc.Index(index_name)\n",
    "print(f\"‚úÖ Conectado ao √≠ndice: {index_name}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc06a86",
   "metadata": {},
   "source": [
    "## 9. Indexando os vetores no Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92540eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Indexados 20 vetores.\n"
     ]
    }
   ],
   "source": [
    "# Reindexa todos os chunks no Pinecone\n",
    "ids = [f\"doc_{i}\" for i in range(len(chunks))]\n",
    "metadata_list = [doc.metadata for doc in chunks]\n",
    "\n",
    "# Formata os vetores para o Pinecone\n",
    "to_upsert = list(zip(ids, vectors.tolist(), metadata_list))\n",
    "\n",
    "# Envia os dados ao √≠ndice\n",
    "index.upsert(vectors=to_upsert)\n",
    "print(f\"‚úÖ Indexados {len(to_upsert)} vetores.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b306904e",
   "metadata": {},
   "source": [
    "## RAG (modelo + Pinecone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cab03f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Conectar e criar √≠ndice Pinecone com dimens√£o 384\n",
    "llm = ChatGroq(model_name='llama-3.3-70b-versatile', temperature=0)\n",
    "\n",
    "index_name = \"ia-turismo\"  \n",
    "\n",
    "\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedder,\n",
    "    index_name=index_name\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "chains = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f659ca5",
   "metadata": {},
   "source": [
    "## 11. Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52852bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template para roteiro tur√≠stico\n",
    "template_roteiro = \"\"\"Voc√™ √© um guia de turismo inteligente.\n",
    "Com base nas informa√ß√µes abaixo, gere um roteiro de viagem personalizado.\n",
    ".Se faltar dado, diga que n√£o encontrou no contexto.\n",
    "Contexto: {context}\n",
    "Pergunta: {question}\n",
    "Roteiro:\"\"\"\n",
    "\n",
    "# Template para informa√ß√µes log√≠sticas\n",
    "template_logistica = \"\"\"Voc√™ √© um assistente de viagem. Com base nas informa√ß√µes abaixo, responda d√∫vidas sobre transporte, acomoda√ß√µes e deslocamentos.\n",
    "Contexto: {context}\n",
    "Pergunta: {question}\n",
    "Resposta:\"\"\"\n",
    "\n",
    "# Template para informa√ß√µes locais (restaurantes, hor√°rios, etc.)\n",
    "template_info_local = \"\"\"Voc√™ √© um guia local. Responda √† pergunta com base nas informa√ß√µes abaixo.\n",
    "Contexto: {context}\n",
    "Pergunta: {question}\n",
    "Resposta:\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78de5b6",
   "metadata": {},
   "source": [
    "## 12. Cadeias Especializadas (Chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a0d84bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chain(template):\n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "    return RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "\n",
    "# Dicion√°rio de cadeias dispon√≠veis\n",
    "chains = {\n",
    "    \"roteiro-viagem\": build_chain(template_roteiro),\n",
    "    \"logistica-transporte\": build_chain(template_logistica),\n",
    "    \"info-local\": build_chain(template_info_local),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24655e2",
   "metadata": {},
   "source": [
    "## 13. Roteador Simples com Classifica√ß√£o por Palavra-chave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72d556fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_question(user_query: str) -> str:\n",
    "    query = user_query.lower()\n",
    "\n",
    "    if any(kw in query for kw in [\"roteiro\", \"itiner√°rio\", \"viagem\", \"dias\"]):\n",
    "        return \"roteiro-viagem\"\n",
    "    elif any(kw in query for kw in [\"metr√¥\", \"√¥nibus\", \"como chegar\", \"transporte\", \"hospedagem\", \"hotel\"]):\n",
    "        return \"logistica-transporte\"\n",
    "    elif any(kw in query for kw in [\"restaurante\", \"funciona\", \"pre√ßo\", \"hor√°rio\", \"ingresso\", \"aberto\"]):\n",
    "        return \"info-local\"\n",
    "    else:\n",
    "        return \"info-local\"  # fallback padr√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf0aa6b",
   "metadata": {},
   "source": [
    "## 14. Fun√ß√£o Final de Consulta (pergunta do usu√°rio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b05a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def responder_pergunta(pergunta: str):\n",
    "    categoria = classify_question(pergunta)\n",
    "    resposta = chains[categoria].run(pergunta)\n",
    "    return resposta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94238383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## ‚ú® IA de Turismo"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Pe√ßa roteiros, sugest√µes de passeios, restaurantes, eventos e mais. Ex: *Roteiro para Amsterd√£ de 3 dias.*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d56d273b1c4addaa90400a6ebd266d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Roteiro para Amsterd√£', layout=Layout(width='100%'), placeholder='Digite sua pergunta aqui...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7d05fd367f4e508d3413909d6f343d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Gerar Resposta ‚úàÔ∏è', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9a3950263d4690a7530f207cbe2700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "# T√≠tulo\n",
    "display(Markdown(\"## ‚ú® IA de Turismo\"))\n",
    "display(Markdown(\"Pe√ßa roteiros, sugest√µes de passeios, restaurantes, eventos e mais. Ex: *Roteiro para Amsterd√£ de 3 dias.*\"))\n",
    "\n",
    "# Campo de pergunta\n",
    "pergunta_input = widgets.Text(\n",
    "    value=\"Roteiro para Amsterd√£\",\n",
    "    placeholder=\"Digite sua pergunta aqui...\",\n",
    "    layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "# Bot√£o\n",
    "botao = widgets.Button(\n",
    "    description=\"Gerar Resposta ‚úàÔ∏è\",\n",
    "    button_style=\"success\"\n",
    ")\n",
    "\n",
    "# √Årea de sa√≠da\n",
    "saida = widgets.Output()\n",
    "\n",
    "# Fun√ß√£o de resposta\n",
    "def gerar_resposta(b):\n",
    "    with saida:\n",
    "        clear_output()\n",
    "        pergunta = pergunta_input.value.strip()\n",
    "        if not pergunta:\n",
    "            display(Markdown(\"‚ö†Ô∏è *Digite uma pergunta.*\"))\n",
    "            return\n",
    "        try:\n",
    "            resposta = responder_pergunta(pergunta)\n",
    "            resposta_formatada = resposta.get(\"result\") if isinstance(resposta, dict) else resposta\n",
    "            display(Markdown(f\"### üì© **Pergunta:** {pergunta}\"))\n",
    "            display(Markdown(f\"### üß≠ **Resposta:**\\n\\n{resposta_formatada}\"))\n",
    "        except Exception as e:\n",
    "            display(Markdown(f\"‚ùå Erro: `{e}`\"))\n",
    "\n",
    "botao.on_click(gerar_resposta)\n",
    "\n",
    "# Exibir interface (‚ö†Ô∏è N√£o colocar como √∫ltima linha!)\n",
    "display(pergunta_input, botao, saida)\n",
    "\n",
    "# Evita duplica√ß√£o: adicione uma string ‚Äúfantasma‚Äù no final\n",
    "\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310 (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
